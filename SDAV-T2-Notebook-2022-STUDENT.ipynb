{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.cems.uwe.ac.uk/~pa-legg/images/uwe_banner.png\">\n",
    "\n",
    "# UFCFEL-15-3 Security Data Analytics and Visualisation\n",
    "# Portfolio Assignment 2: Machine Learning for Malware Analysis (2022)\n",
    "---\n",
    "\n",
    "The completion of this worksheet is worth a **maximum of 35 marks** towards your portfolio assignment for the UFCFEL-15-3 Security Data Analytics and Visualisation (SDAV) module.\n",
    "\n",
    "### Brief\n",
    "---\n",
    "\n",
    "In this task, you have been given a large sample of derived malware features that describe 14 different malware variants (2000 samples of each). The purpose of this task is to understand the underlying concepts of classification, and **your task will be to develop two classifiers that can classify malware varients**. The first part will focus on a small hand-made classifier using only 3 malware classes, to understand the principles of search space and minimisation of a function. The second part will focus on using off-the-shelf libraries to scale up the classification to all 14 classes of malware present in the dataset.\n",
    "\n",
    "### Assessment and Marking\n",
    "---\n",
    "\n",
    "For each question you will see the maximum number of marks you may be awarded for a complete answer in brackets.\n",
    "\n",
    "**Part 1: Developing a Classifier \"by hand\"**\n",
    "\n",
    "* **Task 1:** Find the Centroid point of each of the three groups (3)\n",
    "* **Task 2:** Plot the centroids on a Scatter Plot against the train data colour-coded by group (3)\n",
    "* **Task 3:** For each item in test_data, measure the distance to each centroid point, assign membership to the group of minimum distance, and compare with the expected test data label to obtain a score of successful classifications (12)\n",
    "* **Task 4:** Provide a final accuracy score for the performance of your \"by hand\" classifier (2)\n",
    "\n",
    "**Part 2: Developing a large-scale ML classifier**\n",
    "\n",
    "* **Task 5:** Scale the Input Features for further processing using the StandardScaler function (1)\n",
    "* **Task 6:** Obtain numerical labels for each class using the LabelEncoder function (1)\n",
    "* **(Advanced) Task 7:** Prepare the dataset for ML testing, using the Train-Test-Split function of sklearn (2)\n",
    "* **(Advanced) Task 8:** Use a Multi-Layer Perceptron (MLP) classifier to train a machine learning model, and obtain the accuracy score against your test data. (4)\n",
    "* **(Advanced) Task 9:** Use a Random Forest (RF) classifier to train a machine learning model, and obtain the accuracy score against your test data. (4)\n",
    "* **(Advanced) Task 10:** Show how ML parameters can improve the models to achieve a high accuracy score of over 80% (3)\n",
    "\n",
    "Your submission should be submitted to GitLab so that the notebook is fully rendered and executed.\n",
    " \n",
    "### Contact\n",
    "---\n",
    "\n",
    "Questions about this assignment should be directed to your module leader (Phil.Legg@uwe.ac.uk). You can use the Blackboard Q&A feature to ask questions related to this module and this assignment, as well as the on-site teaching sessions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>224862.0</td>\n",
       "      <td>15842.0</td>\n",
       "      <td>12985.0</td>\n",
       "      <td>7387.0</td>\n",
       "      <td>13132.0</td>\n",
       "      <td>5112.0</td>\n",
       "      <td>8661.0</td>\n",
       "      <td>7990.0</td>\n",
       "      <td>14978.0</td>\n",
       "      <td>5656.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3714.0</td>\n",
       "      <td>2892.0</td>\n",
       "      <td>9344.0</td>\n",
       "      <td>2415.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>3023.0</td>\n",
       "      <td>11949.0</td>\n",
       "      <td>3662.0</td>\n",
       "      <td>5552.0</td>\n",
       "      <td>77433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21802.0</td>\n",
       "      <td>2127.0</td>\n",
       "      <td>2076.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>1622.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>2133.0</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1453.0</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>4882.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24407.0</td>\n",
       "      <td>11682.0</td>\n",
       "      <td>7189.0</td>\n",
       "      <td>6538.0</td>\n",
       "      <td>7687.0</td>\n",
       "      <td>6848.0</td>\n",
       "      <td>4974.0</td>\n",
       "      <td>5377.0</td>\n",
       "      <td>7049.0</td>\n",
       "      <td>11642.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5795.0</td>\n",
       "      <td>6053.0</td>\n",
       "      <td>6426.0</td>\n",
       "      <td>5435.0</td>\n",
       "      <td>4961.0</td>\n",
       "      <td>5026.0</td>\n",
       "      <td>5376.0</td>\n",
       "      <td>4180.0</td>\n",
       "      <td>5685.0</td>\n",
       "      <td>5775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7132.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>...</td>\n",
       "      <td>151.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>940.0</td>\n",
       "      <td>1516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5321.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>...</td>\n",
       "      <td>933.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>924.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>956.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>942.0</td>\n",
       "      <td>1559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>23849.0</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>2649.0</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1042.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>...</td>\n",
       "      <td>993.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>1258.0</td>\n",
       "      <td>1753.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>4342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>9267.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>981.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>819.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>...</td>\n",
       "      <td>998.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>2683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>25357.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>2781.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>4267.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>...</td>\n",
       "      <td>563.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>974.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>29010.0</td>\n",
       "      <td>6476.0</td>\n",
       "      <td>2969.0</td>\n",
       "      <td>5358.0</td>\n",
       "      <td>2827.0</td>\n",
       "      <td>4598.0</td>\n",
       "      <td>2172.0</td>\n",
       "      <td>4045.0</td>\n",
       "      <td>2496.0</td>\n",
       "      <td>3718.0</td>\n",
       "      <td>...</td>\n",
       "      <td>217.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>4005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>4956.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>1109.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>992.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0        1        2       3        4       5       6       7    \\\n",
       "0      224862.0  15842.0  12985.0  7387.0  13132.0  5112.0  8661.0  7990.0   \n",
       "1       21802.0   2127.0   2076.0  2028.0   1871.0  1622.0  1939.0  1502.0   \n",
       "2       24407.0  11682.0   7189.0  6538.0   7687.0  6848.0  4974.0  5377.0   \n",
       "3        7132.0    461.0    647.0   371.0    581.0   269.0   646.0   262.0   \n",
       "4        5321.0   1108.0    985.0   955.0    958.0   890.0   971.0   919.0   \n",
       "...         ...      ...      ...     ...      ...     ...     ...     ...   \n",
       "27995   23849.0   1489.0   1573.0  2649.0   1560.0  1025.0   922.0  1020.0   \n",
       "27996    9267.0   1056.0    981.0   930.0   1573.0   819.0   879.0  1064.0   \n",
       "27997   25357.0    874.0   1008.0  2781.0   1518.0   939.0  4267.0   968.0   \n",
       "27998   29010.0   6476.0   2969.0  5358.0   2827.0  4598.0  2172.0  4045.0   \n",
       "27999    4956.0    185.0     74.0    92.0    133.0    94.0    56.0    46.0   \n",
       "\n",
       "           8        9    ...     246     247     248     249     250     251  \\\n",
       "0      14978.0   5656.0  ...  3714.0  2892.0  9344.0  2415.0  2742.0  3023.0   \n",
       "1       2133.0   1689.0  ...  1664.0  1607.0  1788.0  1394.0  1327.0  1453.0   \n",
       "2       7049.0  11642.0  ...  5795.0  6053.0  6426.0  5435.0  4961.0  5026.0   \n",
       "3        243.0    165.0  ...   151.0   276.0   299.0   294.0   294.0   354.0   \n",
       "4        945.0    963.0  ...   933.0   975.0   945.0   924.0   879.0   952.0   \n",
       "...        ...      ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "27995   1042.0    938.0  ...   993.0   968.0  1165.0  1041.0  1258.0  1753.0   \n",
       "27996   1029.0    893.0  ...   998.0   911.0   990.0  1039.0   930.0   833.0   \n",
       "27997   1103.0   1032.0  ...   563.0   557.0   974.0   706.0   514.0   632.0   \n",
       "27998   2496.0   3718.0  ...   217.0   146.0   544.0   232.0    95.0   140.0   \n",
       "27999    145.0     93.0  ...    50.0    61.0   810.0  1109.0   109.0    62.0   \n",
       "\n",
       "           252     253     254      255  \n",
       "0      11949.0  3662.0  5552.0  77433.0  \n",
       "1       1785.0  1559.0  1755.0   4882.0  \n",
       "2       5376.0  4180.0  5685.0   5775.0  \n",
       "3        506.0   569.0   940.0   1516.0  \n",
       "4        956.0   900.0   942.0   1559.0  \n",
       "...        ...     ...     ...      ...  \n",
       "27995   1203.0   958.0  1315.0   4342.0  \n",
       "27996    904.0   891.0   976.0   2683.0  \n",
       "27997    657.0   584.0   535.0   2431.0  \n",
       "27998    294.0   163.0   182.0   4005.0  \n",
       "27999    209.0   112.0    84.0    992.0  \n",
       "\n",
       "[28000 rows x 256 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv('./T2_data/malware_data.csv', header=None)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>zbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>zbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>zbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>zbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>zbot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0      high\n",
       "1      high\n",
       "2      high\n",
       "3      high\n",
       "4      high\n",
       "...     ...\n",
       "27995  zbot\n",
       "27996  zbot\n",
       "27997  zbot\n",
       "27998  zbot\n",
       "27999  zbot\n",
       "\n",
       "[28000 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('./T2_data/malware_label.csv', header=None)\n",
    "labels = labels.drop(0, axis=1)\n",
    "labels = labels.rename(columns = {1:'label'})\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Developing a Classifier \"by hand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1478119.0</td>\n",
       "      <td>10575.0</td>\n",
       "      <td>wannacry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53767.0</td>\n",
       "      <td>21413.0</td>\n",
       "      <td>wannacry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4085568.0</td>\n",
       "      <td>6635.0</td>\n",
       "      <td>wannacry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2647584.0</td>\n",
       "      <td>19566.0</td>\n",
       "      <td>wannacry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4470838.0</td>\n",
       "      <td>5131.0</td>\n",
       "      <td>wannacry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>69418.0</td>\n",
       "      <td>9673.0</td>\n",
       "      <td>razy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>8060.0</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>razy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4394.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>razy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>183380.0</td>\n",
       "      <td>8477.0</td>\n",
       "      <td>razy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>42945.0</td>\n",
       "      <td>9401.0</td>\n",
       "      <td>razy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x        y    labels\n",
       "0   1478119.0  10575.0  wannacry\n",
       "1     53767.0  21413.0  wannacry\n",
       "2   4085568.0   6635.0  wannacry\n",
       "3   2647584.0  19566.0  wannacry\n",
       "4   4470838.0   5131.0  wannacry\n",
       "..        ...      ...       ...\n",
       "85    69418.0   9673.0      razy\n",
       "86     8060.0   1580.0      razy\n",
       "87     4394.0    540.0      razy\n",
       "88   183380.0   8477.0      razy\n",
       "89    42945.0   9401.0      razy\n",
       "\n",
       "[90 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# DO NOT MODIFY THIS CELL\n",
    "mal1_index = 17000\n",
    "mal2_index = 21000\n",
    "mal3_index = 12000\n",
    "mal_range = 50\n",
    "mal_test_range = 30\n",
    "\n",
    "train_data = np.vstack([ features[mal1_index:mal1_index+mal_range][[0,1]].values, features[mal2_index:mal2_index+mal_range][[0,1]].values, features[mal3_index:mal3_index+mal_range][[0,1]].values ])\n",
    "train_data = pd.DataFrame(train_data)\n",
    "train_labels = np.vstack([ labels[mal1_index:mal1_index+mal_range].values, labels[mal2_index:mal2_index+mal_range].values, labels[mal3_index:mal3_index+mal_range].values ])\n",
    "train_labels = pd.DataFrame(train_labels)\n",
    "train_data['labels'] = train_labels\n",
    "train_data = train_data.rename(columns={0:'x', 1:'y'})\n",
    "\n",
    "test_data = np.vstack([ features[mal1_index+mal_range:mal1_index+mal_range+mal_test_range][[0,1]].values, features[mal2_index+mal_range:mal2_index+mal_range+mal_test_range][[0,1]].values, features[mal3_index+mal_range:mal3_index+mal_range+mal_test_range][[0,1]].values ])\n",
    "test_data = pd.DataFrame(test_data)\n",
    "test_labels = np.vstack([ labels[mal1_index+mal_range:mal1_index+mal_range+mal_test_range].values, labels[mal2_index+mal_range:mal2_index+mal_range+mal_test_range].values, labels[mal3_index+mal_range:mal3_index+mal_range+mal_test_range].values ])\n",
    "test_labels = pd.DataFrame(test_labels)\n",
    "test_data['labels'] = test_labels\n",
    "test_data = test_data.rename(columns={0:'x', 1:'y'})\n",
    "\n",
    "train_data.value_counts('labels')\n",
    "test_data.value_counts('labels')\n",
    "\n",
    "test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1355971f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(train_data['x'], train_data['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Find the Centroid point of each of the three groups (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2181660.66   11087.1 ]\n",
      " [ 100505.22    6158.28]\n",
      " [ 478778.12    3754.04]]\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "# K is the number of cliusters\n",
    "k = 3\n",
    "\n",
    "# I created seperate dataframes for each label, this allowed me to easily calculate the centroid \n",
    "train_wannacry = train_data[train_data['labels'] == 'wannacry']\n",
    "train_razy = train_data[train_data['labels'] == 'razy']\n",
    "train_startsurf = train_data[train_data['labels'] == 'startsurf']\n",
    "\n",
    "# I calculated the centroid for each label and stored them in a numpy array\n",
    "# I do this by finding the mean of the x and y values for each label\n",
    "centroids = []\n",
    "centroids.append([train_wannacry['x'].mean(), train_wannacry['y'].mean()])\n",
    "centroids.append([train_razy['x'].mean(), train_razy['y'].mean()])\n",
    "centroids.append([train_startsurf['x'].mean(), train_startsurf['y'].mean()])\n",
    "centroids = np.array(centroids)\n",
    "\n",
    "\n",
    "# I created a function to generate random centroids between the values 5*10^6 and 45000\n",
    "def generate_initial_points(k):\n",
    "    centroids = []\n",
    "    for i in range(k):\n",
    "        c = [np.random.randint(1, 5 * pow(10, 6)), np.random.randint(1, 45000)]\n",
    "        centroids.append(c)\n",
    "    centroids = np.array(centroids)\n",
    "    return centroids\n",
    "\n",
    "# centroids = generate_initial_points(k)\n",
    "print(centroids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially I only used random centriods for the by hand classifier but by doing this the accuracy was not ideal as there is a cluster of points close (0,0) which has labels from 2 different groups. \n",
    "\n",
    "After having a discussion with Thomas I decided that I would determine the positions of the centroids from the data rather than them being random.\n",
    "\n",
    "By finding the mean of each group and creating centroids off of that it means that when I go to update the centroids it finds a better cluster in the long run and improves the overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEFCAYAAAABjYvXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVzElEQVR4nO3df5Bd5X3f8ffHyODYTbwCZJVKqCK17BS7xYE7gOvW45pWCJqxaIoZMpkiM6rVaZxElqetcf+INLiZsWc6VUUbk9EEJyIT8yMkDmqCUTTYLp1OkFk5GPMjmA2UIA0gBUk4CfUPmW//uM/CZVlJq72XvXvZ92vmzj3ne55z9rmHRZ89z3PuvakqJEkL25uG3QFJ0vAZBpIkw0CSZBhIkjAMJEnAomF3YLbOPPPMWrly5bC7IUkjZe/evX9ZVUum1kc2DFauXMn4+PiwuyFJIyXJU9PVHSaSJBkGkiTDQJKEYSBJwjCQpNEw9XPkBvy5coaBJM13W7bApk2vBEBVd33LloH9CMNAkuazKjhyBLZteyUQNm3qrh85MrArhBOGQZIvJjmQ5KGe2keTPJzkpSSdKe0/k2QiyWNJLu2pr2m1iSTX9dTPSbKn1W9LcupAXpkkvREksHUrbNzYDYA3van7vHFjt54M5MfM5Mrgt4A1U2oPAT8L3PvqPudc4GrgPW2fLyQ5JckpwK8BlwHnAj/X2gJ8HthaVe8EDgPrZ/dSJOkNajIQeg0wCGAGYVBV9wKHptQerarHpmm+Fri1qr5fVU8CE8CF7TFRVU9U1Q+AW4G1SQJ8GLij7b8DuGK2L0aS3pAmh4Z69c4hDMCg5wyWAU/3rO9rtWPVzwCOVNXRKXVJErx6jmDjRnjppVeGjAYYCCP12URJNgAbAFasWDHk3kjSHEhgbOzVcwSTQ0ZjYwMbKhp0GOwHzu5ZX95qHKP+PDCWZFG7Ouht/xpVtR3YDtDpdPzyZkkLw5Yt3SuAyX/4JwNhLucMTtJO4OokpyU5B1gFfAO4H1jV7hw6le4k886qKuBrwJVt/3XAnQPukySNvqn/8A8wCGBmt5beAvwJ8O4k+5KsT/Ivk+wD3g/8UZJdAFX1MHA78AhwN/CJqvpR+6v/F4FdwKPA7a0twKeBTyWZoDuHcNNAX6Ek6YRSA35L81zpdDrl9xlI0slJsreqOlPrvgNZkmQYSJIMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJGb2HchfTHIgyUM9tdOT7E7yeHte3OpJckOSiSQPJjm/Z591rf3jSdb11C9I8u22zw3JgL/lWZJ0QjO5MvgtYM2U2nXAPVW1CrinrQNcBqxqjw3AjdAND2AzcBFwIbB5MkBam4/37Df1Z0mSXmcnDIOquhc4NKW8FtjRlncAV/TUb66u+4CxJGcBlwK7q+pQVR0GdgNr2rafqKr7qqqAm3uOJUmaI7OdM1haVc+05WeBpW15GfB0T7t9rXa8+r5p6pKkOdT3BHL7i74G0JcTSrIhyXiS8YMHD87Fj5SkBWG2YfBcG+KhPR9o9f3A2T3tlrfa8erLp6lPq6q2V1WnqjpLliyZZdclSVPNNgx2ApN3BK0D7uypX9PuKroYeKENJ+0CVidZ3CaOVwO72rbvJrm43UV0Tc+xJElzZNGJGiS5BfgQcGaSfXTvCvoccHuS9cBTwFWt+V3A5cAE8CJwLUBVHUryWeD+1u76qpqclP4Funcs/RjwlfaQJM2hdIf8R0+n06nx8fFhd0OSRkqSvVXVmVr3HciSJMNAkmQYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAk0WcYJNmY5KEkDyf5ZKudnmR3ksfb8+JWT5IbkkwkeTDJ+T3HWdfaP55kXV+vSJJ00mYdBkneC3wcuBA4D/iZJO8ErgPuqapVwD1tHeAyYFV7bABubMc5HdgMXNSOtXkyQCRJc6OfK4O/D+ypqher6ijwv4CfBdYCO1qbHcAVbXktcHN13QeMJTkLuBTYXVWHquowsBtY00e/JEknqZ8weAj4J0nOSPJW4HLgbGBpVT3T2jwLLG3Ly4Cne/bf12rHqkuS5sii2e5YVY8m+Tzwx8DfAA8AP5rSppJUXz3skWQD3SEmVqxYMajDStKC19cEclXdVFUXVNUHgcPAd4Dn2vAP7flAa76f7pXDpOWtdqz6dD9ve1V1qqqzZMmSfrouSerR791E72jPK+jOF3wJ2AlM3hG0DrizLe8Erml3FV0MvNCGk3YBq5MsbhPHq1tNkjRHZj1M1PxekjOAHwKfqKojST4H3J5kPfAUcFVrexfdeYUJ4EXgWoCqOpTks8D9rd31VXWoz35Jkk5CqgY2pD+nOp1OjY+PD7sbkjRSkuytqs7Uuu9AliQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJIk+wyDJpiQPJ3koyS1J3pLknCR7kkwkuS3Jqa3taW19om1f2XOcz7T6Y0ku7fM1SZJO0qzDIMky4JeBTlW9FzgFuBr4PLC1qt4JHAbWt13WA4dbfWtrR5Jz237vAdYAX0hyymz7JUk6ef0OEy0CfizJIuCtwDPAh4E72vYdwBVteW1bp22/JEla/daq+n5VPQlMABf22S9J0kmYdRhU1X7gvwB/QTcEXgD2Akeq6mhrtg9Y1paXAU+3fY+29mf01qfZ51WSbEgynmT84MGDs+26JGmKfoaJFtP9q/4c4O8Ab6M7zPO6qartVdWpqs6SJUtezx8lSQtKP8NE/wx4sqoOVtUPgd8HPgCMtWEjgOXA/ra8HzgboG1/O/B8b32afSRJc6CfMPgL4OIkb21j/5cAjwBfA65sbdYBd7blnW2dtv2rVVWtfnW72+gcYBXwjT76JUk6SYtO3GR6VbUnyR3AN4GjwJ8C24E/Am5N8p9b7aa2y03AbyeZAA7RvYOIqno4ye10g+Qo8Imq+tFs+yVJOnnp/nE+ejqdTo2Pjw+7G5I0UpLsrarO1LrvQJYkGQaSJMNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSSJPsIgybuTPNDz+G6STyY5PcnuJI+358WtfZLckGQiyYNJzu851rrW/vEk6wbxwiRJMzfrMKiqx6rqfVX1PuAC4EXgy8B1wD1VtQq4p60DXAasao8NwI0ASU4HNgMXARcCmycDRJI0NwY1THQJ8OdV9RSwFtjR6juAK9ryWuDm6roPGEtyFnApsLuqDlXVYWA3sGZA/ZIkzcCgwuBq4Ja2vLSqnmnLzwJL2/Iy4Omeffa12rHqr5FkQ5LxJOMHDx4cUNclSX2HQZJTgY8Avzt1W1UVUP3+jJ7jba+qTlV1lixZMqjDStKCN4grg8uAb1bVc239uTb8Q3s+0Or7gbN79lveaseqS5LmyCDC4Od4ZYgIYCcweUfQOuDOnvo17a6ii4EX2nDSLmB1ksVt4nh1q0mS5siifnZO8jbgnwP/tqf8OeD2JOuBp4CrWv0u4HJggu6dR9cCVNWhJJ8F7m/trq+qQ/30S5J0ctId1h89nU6nxsfHh90NSRopSfZWVWdq3XcgS5IMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSWGBhMPUTWkf1E1sladAWTBhs+foWNu3a9HIAVBWbdm1iy9e3DLdjkjQPLIgwqCqOfO8I2/ZsezkQNu3axLY92zjyvSNeIUha8Pr6prNRkYStl24FYNuebWzbsw2AjRdtZOulW0kyzO5J0tAtiCsDeHUgTDIIJKmrrzBIMpbkjiR/luTRJO9PcnqS3Ukeb8+LW9skuSHJRJIHk5zfc5x1rf3jSdb1+6KmMzk01Kt3DkGSFrJ+rwy2AXdX1U8B5wGPAtcB91TVKuCetg5wGbCqPTYANwIkOR3YDFwEXAhsngyQQemdI9h40UZe+pWX2HjRxlfNIUjSQjbrOYMkbwc+CHwMoKp+APwgyVrgQ63ZDuDrwKeBtcDN1f2X9752VXFWa7u7qg614+4G1gC3zLZv0/SVsbeMvWqOYHLIaOwtYw4VSVrw+plAPgc4CPxmkvOAvcBGYGlVPdPaPAssbcvLgKd79t/Xaseqv0aSDXSvKlixYsVJdXbLh7ZQVS//wz8ZCAaBJPU3TLQIOB+4sap+GvgbXhkSAqBdBQxsDKaqtldVp6o6S5YsOen9p/7DbxBIUlc/YbAP2FdVe9r6HXTD4bk2/EN7PtC27wfO7tl/easdqy5JmiOzDoOqehZ4Osm7W+kS4BFgJzB5R9A64M62vBO4pt1VdDHwQhtO2gWsTrK4TRyvbjVJ0hzp901nvwT8TpJTgSeAa+kGzO1J1gNPAVe1tncBlwMTwIutLVV1KMlngftbu+snJ5MlSXMjo3pbZafTqfHx8WF3Q5JGSpK9VdWZWl8w70CWJB2bYSBJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiT6DIMk/zfJt5M8kGS81U5PsjvJ4+15casnyQ1JJpI8mOT8nuOsa+0fT7Kuv5ckSTpZg7gy+KdV9b6e79S8DrinqlYB97R1gMuAVe2xAbgRuuEBbAYuAi4ENk8GiCRpbrwew0RrgR1teQdwRU/95uq6DxhLchZwKbC7qg5V1WFgN7DmdeiXJOkY+g2DAv44yd4kG1ptaVU905afBZa25WXA0z377mu1Y9VfI8mGJONJxg8ePNhn1yVJkxb1uf8/rqr9Sd4B7E7yZ70bq6qSVJ8/o/d424HtAJ1OZ2DHlaSFrq8rg6ra354PAF+mO+b/XBv+oT0faM33A2f37L681Y5VlyTNkVmHQZK3JfnxyWVgNfAQsBOYvCNoHXBnW94JXNPuKroYeKENJ+0CVidZ3CaOV7eaJGmO9DNMtBT4cpLJ43ypqu5Ocj9we5L1wFPAVa39XcDlwATwInAtQFUdSvJZ4P7W7vqqOtRHvyRJJylVozn03ul0anx8fNjdkKSRkmRvz1sBXuY7kCVJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEliAGGQ5JQkf5rkD9v6OUn2JJlIcluSU1v9tLY+0bav7DnGZ1r9sSSX9tsnSdLJGcSVwUbg0Z71zwNbq+qdwGFgfauvBw63+tbWjiTnAlcD7wHWAF9IcsoA+iVJmqG+wiDJcuBfAL/R1gN8GLijNdkBXNGW17Z12vZLWvu1wK1V9f2qehKYAC7sp1+SpJPT75XBfwP+I/BSWz8DOFJVR9v6PmBZW14GPA3Qtr/Q2r9cn2afV0myIcl4kvGDBw/22XVJ0qRZh0GSnwEOVNXeAfbnuKpqe1V1qqqzZMmSufqxkvSGt6iPfT8AfCTJ5cBbgJ8AtgFjSRa1v/6XA/tb+/3A2cC+JIuAtwPP99Qn9e4jSZoDs74yqKrPVNXyqlpJdwL4q1X188DXgCtbs3XAnW15Z1unbf9qVVWrX93uNjoHWAV8Y7b9Wqiqjr8uScfzerzP4NPAp5JM0J0TuKnVbwLOaPVPAdcBVNXDwO3AI8DdwCeq6kevQ7/esLZsgU2bXgmAqu76li3D7JWkUdLPMNHLqurrwNfb8hNMczdQVX0P+Ogx9v9V4FcH0ZeFpgqOHIFt27rrW7d2g2DbNti4sbs9GWoXJY2AgYSBhifpBgB0A2AyFDZu7NYNAkkzkRrRweVOp1Pj4+PD7sa8UQVv6hn0e+klg0DSayXZW1WdqXU/m+gNYHKOoFfvHIIknYhhMOImg2ByjuCll7rP27YZCJJmzjmDEZfA2Nir5wgm5xDGxhwqkjQzzhm8QUy9a8i7iCRNxzmDN7ip//AbBJJOhmEgSTIMJEmGgSQJw0CSxAjfTZTkr4DHht2Pee5M4C+H3Yl5znM0M56nExuVc/R3q+o1Xwgzyu8zeGy626P0iiTjnqPj8xzNjOfpxEb9HDlMJEkyDCRJox0G24fdgRHgOToxz9HMeJ5ObKTP0chOIEuSBmeUrwwkSQNiGEiS5n8YJFmT5LEkE0mum2b7aUlua9v3JFk5hG4O1QzO0ceSHEzyQHv8m2H0c5iSfDHJgSQPHWN7ktzQzuGDSc6f6z4O2wzO0YeSvNDze/Qrc93HYUtydpKvJXkkycNJNk7TZjR/l6pq3j6AU4A/B34SOBX4FnDulDa/APx6W74auG3Y/Z6H5+hjwP8Ydl+HfJ4+CJwPPHSM7ZcDXwECXAzsGXaf5+E5+hDwh8Pu55DP0VnA+W35x4HvTPP/20j+Ls33K4MLgYmqeqKqfgDcCqyd0mYtsKMt3wFckiyoD3CeyTla8KrqXuDQcZqsBW6urvuAsSRnzU3v5ocZnKMFr6qeqapvtuW/Ah4Flk1pNpK/S/M9DJYBT/es7+O1J/7lNlV1FHgBOGNOejc/zOQcAfyrdsl6R5Kz56ZrI2Wm53Ghe3+SbyX5SpL3DLszw9SGpH8a2DNl00j+Ls33MNBg/E9gZVX9Q2A3r1xJSSfjm3Q/1+Y84L8DfzDc7gxPkr8F/B7wyar67rD7MwjzPQz2A71/xS5vtWnbJFkEvB14fk56Nz+c8BxV1fNV9f22+hvABXPUt1Eyk9+1Ba2qvltVf92W7wLenOTMIXdrziV5M90g+J2q+v1pmozk79J8D4P7gVVJzklyKt0J4p1T2uwE1rXlK4GvVpvFWSBOeI6mjFd+hO44p15tJ3BNuxPkYuCFqnpm2J2aT5L87cn5uCQX0v33YyH94UV7/TcBj1bVfz1Gs5H8XZrXn1paVUeT/CKwi+5dM1+sqoeTXA+MV9VOuv9hfjvJBN3Jr6uH1+O5N8Nz9MtJPgIcpXuOPja0Dg9Jklvo3g1zZpJ9wGbgzQBV9evAXXTvApkAXgSuHU5Ph2cG5+hK4N8lOQr8P+DqBfaHF8AHgH8NfDvJA632n4AVMNq/S34chSRp3g8TSZLmgGEgSTIMJEmGgSQJw0CSRsKJPkhwmvZX9Xyg3pdO2N67iSRp/kvyQeCv6X7u0XtP0HYVcDvw4ao6nOQdVXXgePt4ZSBJI2C6DxJM8veS3J1kb5L/neSn2qaPA79WVYfbvscNAjAMJGmUbQd+qaouAP498IVWfxfwriT/J8l9Sdac6EDz+h3IkqTptQ/L+0fA7/Z8av9p7XkRsIruO8qXA/cm+QdVdeRYxzMMJGk0vQk4UlXvm2bbPrpfqvND4Mkk36EbDvcf72CSpBHTPjr7ySQfhZe/bvO8tvkP6F4V0D5Z9l3AE8c7nmEgSSOgfZDgnwDvTrIvyXrg54H1Sb4FPMwr33K4C3g+ySPA14D/UFXH/YRZby2VJHllIEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgSQL+PyIK89zRhMm3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plottong the centroids on the graph\n",
    "plt.scatter(centroids[0,0], centroids[0,1], marker='x', color='r')\n",
    "plt.scatter(centroids[1,0], centroids[1,1], marker='x', color='g')\n",
    "plt.scatter(centroids[2,0], centroids[2,1], marker='x', color='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the centroids I then create 3 lists to contain the clusters \n",
    "\n",
    "I created the function assign_clusters to assign each point of data to one of the clusters. This will be used for when I plot the clusters on the graph. The data points are assigned to each cluster by the shortest distance from the centroid.\n",
    "\n",
    "I then update the centroids by finding the mean position between its point and all of the other data points around it.\n",
    "\n",
    "Once the centroids have been updated I then update the clusters to reflect this as some of the data points may be closer to a different centroid due to the centroids possibly changing positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "\n",
    "\n",
    "cluster1 = []\n",
    "cluster2 = []\n",
    "cluster3 = []\n",
    "\n",
    "all_data = train_data[['x', 'y']]\n",
    "\n",
    "def assign_clusters(centroids, all_data):\n",
    "    cluster1 = []\n",
    "    cluster2 = []\n",
    "    cluster3 = []\n",
    "    for i in range(all_data.shape[0]):\n",
    "        distance1 = np.sqrt(np.abs(all_data.iloc[i, 0] - centroids[0,0]) ** 2 + np.abs(all_data.iloc[i, 1] - centroids[0,1]) ** 2)\n",
    "        distance2 = np.sqrt(np.abs(all_data.iloc[i, 0] - centroids[1,0]) ** 2 + np.abs(all_data.iloc[i, 1] - centroids[1,1]) ** 2)\n",
    "        distance3 = np.sqrt(np.abs(all_data.iloc[i, 0] - centroids[2,0]) ** 2 + np.abs(all_data.iloc[i, 1] - centroids[2,1]) ** 2)\n",
    "        distances = [distance1, distance2, distance3]\n",
    "        if np.argmin(distances) == 0:\n",
    "            cluster1.append([all_data.iloc[i, 0], all_data.iloc[i, 1]])\n",
    "        elif np.argmin(distances) == 1:\n",
    "            cluster2.append([all_data.iloc[i, 0], all_data.iloc[i, 1]])\n",
    "        elif np.argmin(distances) == 2:\n",
    "            cluster3.append([all_data.iloc[i, 0], all_data.iloc[i, 1]])\n",
    "    cluster1 = np.array(cluster1)\n",
    "    cluster2 = np.array(cluster2)\n",
    "    cluster3 = np.array(cluster3)\n",
    "    return cluster1, cluster2, cluster3\n",
    "\n",
    "cluster1, cluster2, cluster3 = assign_clusters(centroids, all_data)\n",
    "\n",
    "\n",
    "# Update centroids\n",
    "centroids = np.array([np.mean(cluster1, axis=0), np.mean(cluster2, axis=0), np.mean(cluster3, axis=0)])\n",
    "\n",
    "# Update clusters\n",
    "\n",
    "all_data = np.vstack([cluster1, cluster2, cluster3])\n",
    "all_data = pd.DataFrame(all_data)\n",
    "cluster1, cluster2, cluster3 = assign_clusters(centroids, all_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Plot the centroids on a Scatter Plot against the train data colour-coded by group (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then plot the data points on the same graph as the centroids\n",
    "\n",
    "The centroids are plotted as X's\n",
    "The data points are plotted as dots \n",
    "\n",
    "The data is then coloured coded depending on the centroid that it grouped to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ANSWER\n",
    "plt.scatter(cluster1[:,0], cluster1[:,1], color='r')\n",
    "plt.scatter(cluster2[:,0], cluster2[:,1], color='g')\n",
    "plt.scatter(cluster3[:,0], cluster3[:,1], color='b')\n",
    "\n",
    "plt.scatter(centroids[0,0], centroids[0,1], marker='x', color='r')\n",
    "plt.scatter(centroids[1,0], centroids[1,1], marker='x', color='g')\n",
    "plt.scatter(centroids[2,0], centroids[2,1], marker='x', color='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: For each item in test_data, measure the distance to each centroid point, assign membership to the group of minimum distance, and compare with the expected test data label to obtain a score of successful classifications (12)\n",
    "\n",
    "*Hint: You may find the clustering activity worksheet helpful for how to approach this task*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# I copied the test data to avoid altering the base data\n",
    "test_data = test_data.copy()\n",
    "\n",
    "# I then assign the test data to three new clusters depening on the centroids that have previously been created\n",
    "test_cluster1, test_cluster2, test_cluster3 = assign_clusters(centroids, test_data[['x', 'y']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "wannacry    16\n",
      "dtype: int64\n",
      "\n",
      "labels\n",
      "razy         30\n",
      "startsurf    13\n",
      "wannacry     10\n",
      "dtype: int64\n",
      "\n",
      "labels\n",
      "startsurf    17\n",
      "wannacry      4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# I created 3 new arrays to store the labels for each cluster\n",
    "test_cluster1_labels = []\n",
    "test_cluster2_labels = []\n",
    "test_cluster3_labels = []\n",
    "\n",
    "# I then loop through each cluster and append the label for each data point into the corresponding new array\n",
    "for i in test_cluster1:\n",
    "\n",
    "    label = test_data[(test_data['x'] == i[0]) & (test_data['y'] == i[1])]['labels'].values[0]\n",
    "    test_cluster1_labels.append(label)\n",
    "\n",
    "for i in test_cluster2:\n",
    "\n",
    "    label = test_data[(test_data['x'] == i[0]) & (test_data['y'] == i[1])]['labels'].values[0]\n",
    "    test_cluster2_labels.append(label)\n",
    "\n",
    "for i in test_cluster3:\n",
    "\n",
    "    label = test_data[(test_data['x'] == i[0]) & (test_data['y'] == i[1])]['labels'].values[0]\n",
    "    test_cluster3_labels.append(label)\n",
    "\n",
    "# I then convert the arrays into dataframes \n",
    "test_cluster1_labels = pd.DataFrame(test_cluster1_labels, columns=['labels'])\n",
    "test_cluster2_labels = pd.DataFrame(test_cluster2_labels, columns=['labels'])\n",
    "test_cluster3_labels = pd.DataFrame(test_cluster3_labels, columns=['labels'])\n",
    "\n",
    "# I then group each cluster by the different labels and count the number of each label for testing purposes\n",
    "print(test_cluster1_labels.groupby('labels').size())\n",
    "print()\n",
    "print(test_cluster2_labels.groupby('labels').size())\n",
    "print()\n",
    "print(test_cluster3_labels.groupby('labels').size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the test data with the centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x17fa72880>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.scatter(test_cluster1[:,0], test_cluster1[:,1], color='r')\n",
    "plt.scatter(test_cluster2[:,0], test_cluster2[:,1], color='g')\n",
    "plt.scatter(test_cluster3[:,0], test_cluster3[:,1], color='b')\n",
    "\n",
    "\n",
    "plt.scatter(centroids[0,0], centroids[0,1], marker='x', color='r')\n",
    "plt.scatter(centroids[1,0], centroids[1,1], marker='x', color='g')\n",
    "plt.scatter(centroids[2,0], centroids[2,1], marker='x', color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Provide a final accuracy score for the performance of your \"by hand\" classifier (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "# I work out the number of correct labels for each cluster by counting the occurences of each label in the 3 clusters\n",
    "# and taking the highest value from each as the correct label\n",
    "\n",
    "cluster1_correct = test_cluster1_labels['labels'].value_counts()[0]\n",
    "cluster2_correct = test_cluster2_labels['labels'].value_counts()[0]\n",
    "cluster3_correct = test_cluster3_labels['labels'].value_counts()[0]\n",
    "\n",
    "# I then divide the sum of all of the correct labels by 90 (the amount of test data) to get the final accuracy\n",
    "final_accuracy = (cluster1_correct + cluster2_correct + cluster3_correct) / len(test_data)\n",
    "print(final_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Developing a large-scale ML classifier\n",
    "\n",
    "We will now extend the earlier principles for the full dataset. Essentially the task is the same, we want to find the parameters that allow us to clearly separate groups for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 5: Scale the Input Features for further processing using the StandardScaler function (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.097820</td>\n",
       "      <td>0.672159</td>\n",
       "      <td>0.826630</td>\n",
       "      <td>0.380661</td>\n",
       "      <td>0.647650</td>\n",
       "      <td>0.204495</td>\n",
       "      <td>0.792002</td>\n",
       "      <td>0.691117</td>\n",
       "      <td>1.028243</td>\n",
       "      <td>0.432558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191715</td>\n",
       "      <td>0.044177</td>\n",
       "      <td>0.845365</td>\n",
       "      <td>-0.010620</td>\n",
       "      <td>0.038420</td>\n",
       "      <td>0.068183</td>\n",
       "      <td>1.190714</td>\n",
       "      <td>0.135741</td>\n",
       "      <td>0.178144</td>\n",
       "      <td>0.406173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.355085</td>\n",
       "      <td>-0.291567</td>\n",
       "      <td>-0.274569</td>\n",
       "      <td>-0.254820</td>\n",
       "      <td>-0.323318</td>\n",
       "      <td>-0.234858</td>\n",
       "      <td>-0.178266</td>\n",
       "      <td>-0.244002</td>\n",
       "      <td>-0.310024</td>\n",
       "      <td>-0.182924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155188</td>\n",
       "      <td>-0.155994</td>\n",
       "      <td>-0.248598</td>\n",
       "      <td>-0.175093</td>\n",
       "      <td>-0.166129</td>\n",
       "      <td>-0.179846</td>\n",
       "      <td>-0.248456</td>\n",
       "      <td>-0.168900</td>\n",
       "      <td>-0.218099</td>\n",
       "      <td>-0.238666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.351784</td>\n",
       "      <td>0.379844</td>\n",
       "      <td>0.241558</td>\n",
       "      <td>0.279985</td>\n",
       "      <td>0.178160</td>\n",
       "      <td>0.423038</td>\n",
       "      <td>0.259812</td>\n",
       "      <td>0.314504</td>\n",
       "      <td>0.202153</td>\n",
       "      <td>1.361289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543863</td>\n",
       "      <td>0.536584</td>\n",
       "      <td>0.422895</td>\n",
       "      <td>0.475873</td>\n",
       "      <td>0.359192</td>\n",
       "      <td>0.384618</td>\n",
       "      <td>0.260011</td>\n",
       "      <td>0.210779</td>\n",
       "      <td>0.192024</td>\n",
       "      <td>-0.230729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.373671</td>\n",
       "      <td>-0.408634</td>\n",
       "      <td>-0.418818</td>\n",
       "      <td>-0.451310</td>\n",
       "      <td>-0.434547</td>\n",
       "      <td>-0.405185</td>\n",
       "      <td>-0.364900</td>\n",
       "      <td>-0.422724</td>\n",
       "      <td>-0.506936</td>\n",
       "      <td>-0.419373</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.411219</td>\n",
       "      <td>-0.363332</td>\n",
       "      <td>-0.464176</td>\n",
       "      <td>-0.352293</td>\n",
       "      <td>-0.315456</td>\n",
       "      <td>-0.353466</td>\n",
       "      <td>-0.429556</td>\n",
       "      <td>-0.312311</td>\n",
       "      <td>-0.303149</td>\n",
       "      <td>-0.268583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.375965</td>\n",
       "      <td>-0.363170</td>\n",
       "      <td>-0.384699</td>\n",
       "      <td>-0.382059</td>\n",
       "      <td>-0.402040</td>\n",
       "      <td>-0.327008</td>\n",
       "      <td>-0.317989</td>\n",
       "      <td>-0.328030</td>\n",
       "      <td>-0.433797</td>\n",
       "      <td>-0.295563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278888</td>\n",
       "      <td>-0.254445</td>\n",
       "      <td>-0.370648</td>\n",
       "      <td>-0.250806</td>\n",
       "      <td>-0.230890</td>\n",
       "      <td>-0.258994</td>\n",
       "      <td>-0.365838</td>\n",
       "      <td>-0.264363</td>\n",
       "      <td>-0.302941</td>\n",
       "      <td>-0.268201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>-0.352491</td>\n",
       "      <td>-0.336398</td>\n",
       "      <td>-0.325344</td>\n",
       "      <td>-0.181181</td>\n",
       "      <td>-0.350134</td>\n",
       "      <td>-0.310013</td>\n",
       "      <td>-0.325062</td>\n",
       "      <td>-0.313473</td>\n",
       "      <td>-0.423691</td>\n",
       "      <td>-0.299442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268735</td>\n",
       "      <td>-0.255535</td>\n",
       "      <td>-0.338796</td>\n",
       "      <td>-0.231958</td>\n",
       "      <td>-0.176103</td>\n",
       "      <td>-0.132452</td>\n",
       "      <td>-0.330864</td>\n",
       "      <td>-0.255961</td>\n",
       "      <td>-0.264016</td>\n",
       "      <td>-0.243465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>-0.370966</td>\n",
       "      <td>-0.366824</td>\n",
       "      <td>-0.385103</td>\n",
       "      <td>-0.385023</td>\n",
       "      <td>-0.349013</td>\n",
       "      <td>-0.335946</td>\n",
       "      <td>-0.331268</td>\n",
       "      <td>-0.307131</td>\n",
       "      <td>-0.425046</td>\n",
       "      <td>-0.306423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267889</td>\n",
       "      <td>-0.264414</td>\n",
       "      <td>-0.364133</td>\n",
       "      <td>-0.232280</td>\n",
       "      <td>-0.223518</td>\n",
       "      <td>-0.277794</td>\n",
       "      <td>-0.373201</td>\n",
       "      <td>-0.265666</td>\n",
       "      <td>-0.299393</td>\n",
       "      <td>-0.258211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>-0.350581</td>\n",
       "      <td>-0.379613</td>\n",
       "      <td>-0.382378</td>\n",
       "      <td>-0.165528</td>\n",
       "      <td>-0.353755</td>\n",
       "      <td>-0.320840</td>\n",
       "      <td>0.157763</td>\n",
       "      <td>-0.320967</td>\n",
       "      <td>-0.417336</td>\n",
       "      <td>-0.284857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341500</td>\n",
       "      <td>-0.319559</td>\n",
       "      <td>-0.366449</td>\n",
       "      <td>-0.285923</td>\n",
       "      <td>-0.283654</td>\n",
       "      <td>-0.309548</td>\n",
       "      <td>-0.408175</td>\n",
       "      <td>-0.310138</td>\n",
       "      <td>-0.345414</td>\n",
       "      <td>-0.260450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>-0.345952</td>\n",
       "      <td>0.014028</td>\n",
       "      <td>-0.184426</td>\n",
       "      <td>0.140058</td>\n",
       "      <td>-0.240888</td>\n",
       "      <td>0.139788</td>\n",
       "      <td>-0.144634</td>\n",
       "      <td>0.122522</td>\n",
       "      <td>-0.272205</td>\n",
       "      <td>0.131877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400050</td>\n",
       "      <td>-0.383582</td>\n",
       "      <td>-0.428705</td>\n",
       "      <td>-0.362280</td>\n",
       "      <td>-0.344223</td>\n",
       "      <td>-0.387274</td>\n",
       "      <td>-0.459574</td>\n",
       "      <td>-0.371125</td>\n",
       "      <td>-0.382252</td>\n",
       "      <td>-0.246461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>-0.376427</td>\n",
       "      <td>-0.428028</td>\n",
       "      <td>-0.476659</td>\n",
       "      <td>-0.484395</td>\n",
       "      <td>-0.473175</td>\n",
       "      <td>-0.427216</td>\n",
       "      <td>-0.450062</td>\n",
       "      <td>-0.453856</td>\n",
       "      <td>-0.517146</td>\n",
       "      <td>-0.430544</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.428310</td>\n",
       "      <td>-0.396823</td>\n",
       "      <td>-0.390193</td>\n",
       "      <td>-0.221004</td>\n",
       "      <td>-0.342199</td>\n",
       "      <td>-0.399596</td>\n",
       "      <td>-0.471610</td>\n",
       "      <td>-0.378512</td>\n",
       "      <td>-0.392479</td>\n",
       "      <td>-0.273240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0     -0.097820  0.672159  0.826630  0.380661  0.647650  0.204495  0.792002   \n",
       "1     -0.355085 -0.291567 -0.274569 -0.254820 -0.323318 -0.234858 -0.178266   \n",
       "2     -0.351784  0.379844  0.241558  0.279985  0.178160  0.423038  0.259812   \n",
       "3     -0.373671 -0.408634 -0.418818 -0.451310 -0.434547 -0.405185 -0.364900   \n",
       "4     -0.375965 -0.363170 -0.384699 -0.382059 -0.402040 -0.327008 -0.317989   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "27995 -0.352491 -0.336398 -0.325344 -0.181181 -0.350134 -0.310013 -0.325062   \n",
       "27996 -0.370966 -0.366824 -0.385103 -0.385023 -0.349013 -0.335946 -0.331268   \n",
       "27997 -0.350581 -0.379613 -0.382378 -0.165528 -0.353755 -0.320840  0.157763   \n",
       "27998 -0.345952  0.014028 -0.184426  0.140058 -0.240888  0.139788 -0.144634   \n",
       "27999 -0.376427 -0.428028 -0.476659 -0.484395 -0.473175 -0.427216 -0.450062   \n",
       "\n",
       "            7         8         9    ...       246       247       248  \\\n",
       "0      0.691117  1.028243  0.432558  ...  0.191715  0.044177  0.845365   \n",
       "1     -0.244002 -0.310024 -0.182924  ... -0.155188 -0.155994 -0.248598   \n",
       "2      0.314504  0.202153  1.361289  ...  0.543863  0.536584  0.422895   \n",
       "3     -0.422724 -0.506936 -0.419373  ... -0.411219 -0.363332 -0.464176   \n",
       "4     -0.328030 -0.433797 -0.295563  ... -0.278888 -0.254445 -0.370648   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "27995 -0.313473 -0.423691 -0.299442  ... -0.268735 -0.255535 -0.338796   \n",
       "27996 -0.307131 -0.425046 -0.306423  ... -0.267889 -0.264414 -0.364133   \n",
       "27997 -0.320967 -0.417336 -0.284857  ... -0.341500 -0.319559 -0.366449   \n",
       "27998  0.122522 -0.272205  0.131877  ... -0.400050 -0.383582 -0.428705   \n",
       "27999 -0.453856 -0.517146 -0.430544  ... -0.428310 -0.396823 -0.390193   \n",
       "\n",
       "            249       250       251       252       253       254       255  \n",
       "0     -0.010620  0.038420  0.068183  1.190714  0.135741  0.178144  0.406173  \n",
       "1     -0.175093 -0.166129 -0.179846 -0.248456 -0.168900 -0.218099 -0.238666  \n",
       "2      0.475873  0.359192  0.384618  0.260011  0.210779  0.192024 -0.230729  \n",
       "3     -0.352293 -0.315456 -0.353466 -0.429556 -0.312311 -0.303149 -0.268583  \n",
       "4     -0.250806 -0.230890 -0.258994 -0.365838 -0.264363 -0.302941 -0.268201  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "27995 -0.231958 -0.176103 -0.132452 -0.330864 -0.255961 -0.264016 -0.243465  \n",
       "27996 -0.232280 -0.223518 -0.277794 -0.373201 -0.265666 -0.299393 -0.258211  \n",
       "27997 -0.285923 -0.283654 -0.309548 -0.408175 -0.310138 -0.345414 -0.260450  \n",
       "27998 -0.362280 -0.344223 -0.387274 -0.459574 -0.371125 -0.382252 -0.246461  \n",
       "27999 -0.221004 -0.342199 -0.399596 -0.471610 -0.378512 -0.392479 -0.273240  \n",
       "\n",
       "[28000 rows x 256 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# I created a copy of the features to avoid altering the base data\n",
    "full_data = features.copy()\n",
    "\n",
    "# I then created a new scaler object which I then use to scale the data\n",
    "scaler = StandardScaler()\n",
    "full_data = scaler.fit_transform(full_data)\n",
    "full_data = pd.DataFrame(full_data)\n",
    "\n",
    "full_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Obtain numerical labels for each class using the LabelEncoder function (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I import the LabelEncoder from sklearn, I then create a label encoder object and use it to encode the labels into numerical form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobmoran/miniforge3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels\n",
       "0           7\n",
       "1           7\n",
       "2           7\n",
       "3           7\n",
       "4           7\n",
       "...       ...\n",
       "27995      13\n",
       "27996      13\n",
       "27997      13\n",
       "27998      13\n",
       "27999      13\n",
       "\n",
       "[28000 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data_labels = labels.copy()\n",
    "data_labels = le.fit_transform(data_labels)\n",
    "data_labels = pd.DataFrame(data_labels)\n",
    "data_labels = data_labels.rename(columns={0:'labels'})\n",
    "data_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Advanced) Task 7: Prepare the dataset for ML testing, using the Train-Test-Split function of sklearn (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the train_test_split function from sklearn to split the data and the labels into training and testing sets with their corresponding labels. The test size shows the proportion of data that will be allocated to the testing dataset. 0.2 would resemble 20% of the data. The random state provides the seed so that these results can be replicated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(full_data, data_labels, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Advanced) Task 8: Use a Multi-Layer Perceptron (MLP) classifier to train a machine learning model, and obtain the accuracy score against your test data. (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created an MLP classifier with the variables hidden layer size and max iter. By changing these variables and using others as well will determine the accuracy of the MLP classifier. I then calculate the accuracy score by using the accuracy score function eith the labels from the data and the predictions made by the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7430357142857142\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=5000)\n",
    "mlp.fit(train_x, train_y['labels'])\n",
    "predictions = mlp.predict(test_x)\n",
    "accuracy = accuracy_score(test_y['labels'], predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Advanced) Task 9: Use a Random Forest (RF) classifier to train a machine learning model, and obtain the accuracy score against your test data. (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created an Random forest classifier with the variables n_estimators and max depth and random state. By changing these variables and using others as well will determine the accuracy of the classifier. I then calculate the accuracy score by using the accuracy score function with labels from the data and the predictions made by the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8819642857142858\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=20, random_state=0)\n",
    "rf.fit(train_x, train_y['labels'])\n",
    "predictions = rf.predict(test_x)\n",
    "accuracy = accuracy_score(test_y['labels'], predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Advanced) Task 10: Show how ML parameters can improve the models to achieve a high accuracy score of over 80% (3)\n",
    "\n",
    "*Marks wil be awarded for how your tuning improves accuracy beyond 80%.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to use grid search to refine my classifiers to get the best result. I will put a range of variable values in and gridsearch will test the combinations to find the best result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "MLPclf = GridSearchCV(MLPClassifier(), {'hidden_layer_sizes': [(10, 10, 10), (100, 100, 100), (100, 100, 100, 100, 100)], 'max_iter': [5000, 10000, 15000]}, cv=5)\n",
    "MLPclf.fit(train_x, train_y['labels'])\n",
    "print(MLPclf.best_params_)\n",
    "\n",
    "RFclf = GridSearchCV(RandomForestClassifier(), {'n_estimators': [100, 200, 300], 'max_depth': [2, 3, 4]}, cv=5)\n",
    "RFclf.fit(train_x, train_y['labels'])\n",
    "print(RFclf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8798214285714285\n",
      "0.8208928571428571\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, max_depth=20)\n",
    "rf.fit(train_x, train_y['labels'])\n",
    "predictions = rf.predict(test_x)\n",
    "accuracy = accuracy_score(test_y, predictions)\n",
    "print(accuracy)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(400), max_iter=7000) \n",
    "mlp.fit(train_x, train_y['labels'])\n",
    "predictions = mlp.predict(test_x)\n",
    "accuracy = accuracy_score(test_y, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see that both scores have now increased above 80%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10 | packaged by conda-forge | (main, Feb  1 2022, 21:27:43) \n[Clang 11.1.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb62b96173824a563bc291d40df371523dc6df89411c8b31ffc6308105513ad2"
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
